#第一题：采用Python爬虫采集大众品牌汽车在网上的报价，最终导出为CSV格式文件
import requests
from bs4 import BeautifulSoup
import  pandas as pd
# 请求URL
url = 'http://car.bitauto.com/xuanchegongju/?l=8&mid=8'
# 得到页面的内容
headers={'user-agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36'}
html=requests.get(url,headers=headers,timeout=10)
content = html.text
# 通过content创建BeautifulSoup对象
soup = BeautifulSoup(content, 'html.parser')

temp = soup.find('div', class_='search-result-list')
# df = pd.DataFrame(columns=['data-id','cx-name','cx-price','img'])
df = pd.DataFrame(columns=['车型名称','最低价格','最高价格','产品图片链接'])
cx_list = soup.find_all('div', class_='search-result-list-item')
for cx in cx_list:
    tp={}
    tp['车型名称'] = cx.find('p', class_='cx-name text-hover').text
    a = cx.find('p', class_='cx-price').text
    # print(a)
    if a!='暂无':
        b=tuple(a.split('-'))
        tp['最低价格'] = b[0]+'万'
        tp['最高价格'] = b[1]
    else:
        tp['最低价格'] = '暂无'
        tp['最高价格'] = '暂无'
    tp['产品图片链接'] = 'http:' + cx.img['src']
    df = df.append(tp, ignore_index=True)
# print(df)
df.to_csv('car-price-data.csv',index=False)


#第二题：使用Apriori算法，挖掘订单中的频繁项集及关联规则
import pandas as pd
import numpy as np
from efficient_apriori import apriori

dataset = pd.read_csv('./ordersheet.csv',encoding='gb18030')
print(dataset.shape)

orders_series = dataset.set_index('客户ID')['产品名称']
# print(orders_series)
# orders_series.to_csv('car-price-data.csv',index=False)

transactions = []
temp_index = 0
for i, v in orders_series.items():
    if i != temp_index:
        temp_set = set()
        temp_index = i
        temp_set.add(v)
        transactions.append(temp_set)
    else:
        temp_set.add(v)

itemsets,rules=apriori(transactions,min_support=0.02,min_confidence=0.5)
print('频繁项集：',itemsets)
print('关联规则：',rules)


